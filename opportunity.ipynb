{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate train and test train_test_split function' \n",
    "def train_test_split_local(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    train_test_split(y, shuffle=False)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def read(file_name, fheader, fuser, ftrial):\n",
    "    fsadl1 = pd.read_csv(file_name, sep=' ', header=None)\n",
    "    fdata = fsadl1.iloc[:, :243]\n",
    "    fdata.columns = fheader\n",
    "    fdata=fdata[fdata.columns[np.r_[0:45,50:58,63:71,76:84,89:97,102:133]]]\n",
    "    flabels = fsadl1.iloc[:,243]\n",
    "    ## Preprocessing data\n",
    "    #find and remove rows with all nulls\n",
    "    fidx=fdata.index[fdata.isnull().all(1)] #1 is the axis for rows\n",
    "    #select data not in idx, that is data that is not all null\n",
    "    fdata = fdata[~fdata.index.isin(fidx)] \n",
    "    #same for labels\n",
    "    flabels = flabels[~flabels.index.isin(fidx)]\n",
    "\n",
    "    #see how many there are of each label\n",
    "    #what does it mean ?\n",
    "    flabels.value_counts()\n",
    "\n",
    "\n",
    "    #fill missing values\n",
    "    fdata = fdata.fillna(method='ffill',axis=1)\n",
    "\n",
    "\n",
    "    fdata['user'] = fuser\n",
    "    fdata['trial'] = ftrial\n",
    "    return fdata, flabels\n",
    "    \n",
    "def windowing(fdata, window_number, window_text, porcentage, flabels, frol):\n",
    "    ffiltered_data = fdata[columns].rolling(frol).median()\n",
    "    ffiltered_data['MILLISEC'] = fdata.MILLISEC\n",
    "\n",
    "\n",
    "    # Windowing and Feature Extraction\n",
    "    ffiltered_data['time']=pd.to_datetime(fdata.MILLISEC,unit='ms')\n",
    "    ffiltered_data.index=ffiltered_data.time\n",
    "    #calculate mean over a 1 second window\n",
    "    keep = ffiltered_data.time.dt.microsecond/window_number %porcentage\n",
    "    keep = keep - keep.shift() < 0\n",
    "\n",
    "    means = ffiltered_data[columns].rolling(window_text).mean()[keep]\n",
    "    means.columns = [str(col) + '_mean' for col in means.columns]\n",
    "    variances = ffiltered_data[columns].rolling(window_text).var()[keep]\n",
    "    variances.columns = [str(col) + '_var' for col in variances.columns]\n",
    "\n",
    "    #talk about apply function\n",
    "    flabels.index = ffiltered_data.time\n",
    "    mode_labels = flabels.rolling(window_text).apply(lambda x:mode(x)[0])[keep]\n",
    "\n",
    "    #all features\n",
    "    fall_features = pd.concat([means, variances],axis=1)\n",
    "    fall_features['label'] = mode_labels\n",
    "    fall_features['user'] = user\n",
    "    fall_features['trial'] = trial\n",
    "    \n",
    "    return fall_features\n",
    "\n",
    "def plot_confusion_matrix(cm, names, title='MATRIZ DE CONFUSIÃ“N', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Clase real')\n",
    "    plt.xlabel('Clase predicha')\n",
    "\n",
    "\n",
    "def excercise_1 (fall_data, estimators):\n",
    "    # Excercise 1\n",
    "    # Random train test split\n",
    "\n",
    "    # Labels are the values we want to predict\n",
    "    labels = np.array(fall_data['label'])\n",
    "\n",
    "    # Remove the labels from the features\n",
    "    # axis 1 refers to the columns\n",
    "    features = fall_data.drop('label', axis = 1)\n",
    "    features = features.drop('user', axis = 1)\n",
    "    features = features.drop('trial', axis = 1)\n",
    "\n",
    "\n",
    "    # Saving feature names for later use\n",
    "    feature_list = list(features.columns)\n",
    "\n",
    "    # Convert to numpy array\n",
    "    features = np.array(features)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split_local(features, labels)\n",
    "\n",
    "    print('X_train:', X_train.shape)\n",
    "    print('X_test:', X_test.shape)\n",
    "    print('y_train:', y_train.shape)\n",
    "    print('y_test:', y_test.shape)\n",
    "\n",
    "\n",
    "    classifier = RandomForestClassifier(n_estimators=estimators, random_state=0)  \n",
    "    classifier.fit(X_train, y_train)  \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    labels = [0,1,2,4,5]\n",
    "\n",
    "    print(\"\\n _______________________________________________________\")  \n",
    "    print(\"confusion matrix: \\n\")  \n",
    "    print(confusion_matrix(y_test,y_pred))  \n",
    "    print(\"\\n _______________________________________________________\")  \n",
    "    print(\"classification report: \\n\")  \n",
    "    print(classification_report(y_test,y_pred))  \n",
    "    print(\"_______________________________________________________\")  \n",
    "    print(\"accuracy score: \" + str(accuracy_score(y_test, y_pred)))  \n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_confusion_matrix(confusion_matrix(y_test,y_pred), labels)\n",
    "\n",
    "def excercise_2 (fall_data, estimators):\n",
    "    # Excercise 2\n",
    "    # user 1 2 3 train test 4\n",
    "\n",
    "    # Labels are the values we want to predict\n",
    "    # Remove the labels from the features\n",
    "    # axis 1 refers to the columns\n",
    "\n",
    "    user123 = fall_data[fall_data['user'].isin([1, 2, 3])]\n",
    "    user4 = fall_data[fall_data['user'].isin([4])]\n",
    "\n",
    "\n",
    "    y_train_2 = np.array(user123['label'])\n",
    "    y_test_2 = np.array(user4['label'])\n",
    "\n",
    "    user123 = user123.drop('label', axis = 1)\n",
    "    user123 = user123.drop('user', axis = 1)\n",
    "    user123 = user123.drop('trial', axis = 1)\n",
    "\n",
    "    user4 = user4.drop('label', axis = 1)\n",
    "    user4 = user4.drop('user', axis = 1)\n",
    "    user4 = user4.drop('trial', axis = 1)\n",
    "\n",
    "    X_train_2 = np.array(user123)\n",
    "    X_test_2 = np.array(user4)\n",
    "    print('X_train_2:', X_train_2.shape)\n",
    "    print('X_test_2:', X_test_2.shape)\n",
    "    print('y_train_2:', y_train_2.shape)\n",
    "    print('y_test_2:', y_test_2.shape)\n",
    "\n",
    "\n",
    "    classifier2 = RandomForestClassifier(n_estimators=estimators, random_state=0)  \n",
    "    classifier2.fit(X_train_2, y_train_2)  \n",
    "    y_pred_2 = classifier2.predict(X_test_2)\n",
    "\n",
    "    print(\"\\n _______________________________________________________\")  \n",
    "    print(\"confusion matrix: \\n\")  \n",
    "    print(confusion_matrix(y_test_2,y_pred_2))  \n",
    "    print(\"\\n _______________________________________________________\")  \n",
    "    print(\"classification report: \\n\")  \n",
    "    print(classification_report(y_test_2,y_pred_2))  \n",
    "    print(\"_______________________________________________________\")  \n",
    "    print(\"accuracy score: \" +str(accuracy_score(y_test_2, y_pred_2)))\n",
    "\n",
    "    labels = [0,1,2,4,5]\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_confusion_matrix(confusion_matrix(y_test_2,y_pred_2), labels)\n",
    "\n",
    "def excercise_3 (fall_data, estimators):  \n",
    "    # Excercise 3\n",
    "    #  1,2,3 and drill session as training data and trials 4 and 5 as test data.\n",
    "\n",
    "    # Labels are the values we want to predict\n",
    "    # Remove the labels from the features\n",
    "    # axis 1 refers to the columns\n",
    "\n",
    "    trial1236 = fall_data[fall_data['trial'].isin([1, 2, 3, 6])]\n",
    "    trial45 = fall_data[fall_data['trial'].isin([4, 5])]\n",
    "\n",
    "    y_train_3 = np.array(trial1236['label'])\n",
    "    y_test_3 = np.array(trial45['label'])\n",
    "\n",
    "    trial1236 = trial1236.drop('label', axis = 1)\n",
    "    trial1236 = trial1236.drop('user', axis = 1)\n",
    "    trial1236 = trial1236.drop('trial', axis = 1)\n",
    "\n",
    "    trial45 = trial45.drop('label', axis = 1)\n",
    "    trial45 = trial45.drop('user', axis = 1)\n",
    "    trial45 = trial45.drop('trial', axis = 1)\n",
    "\n",
    "    X_train_3 = np.array(trial1236)\n",
    "    X_test_3 = np.array(trial45)\n",
    "\n",
    "    print('X_train_3:', X_train_3.shape)\n",
    "    print('X_test_3:', X_test_3.shape)\n",
    "    print('y_train_3:', y_train_3.shape)\n",
    "    print('y_test_3:', y_test_3.shape)\n",
    "\n",
    "\n",
    "    classifier = RandomForestClassifier(n_estimators=estimators, random_state=0)  \n",
    "    classifier.fit(X_train_3, y_train_3)  \n",
    "    y_pred_3 = classifier.predict(X_test_3)\n",
    "\n",
    "\n",
    "    print(\"\\n _______________________________________________________\")  \n",
    "    print(\"confusion matrix: \\n\")  \n",
    "    print(confusion_matrix(y_test_3,y_pred_3))  \n",
    "    print(\"\\n _______________________________________________________\")  \n",
    "    print(\"classification report: \\n\")  \n",
    "    print(classification_report(y_test_3,y_pred_3))  \n",
    "    print(\"_______________________________________________________\")  \n",
    "    print(\"accuracy score: \" + str(accuracy_score(y_test_3, y_pred_3)))\n",
    "\n",
    "    labels = [0,1,2,4,5]\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plot_confusion_matrix(confusion_matrix(y_test_3,y_pred_3), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "path = 'dataset/' #enter thepath for the dataset folder\n",
    "header_path = 'header.csv' #enter the path for the header file\n",
    "header=pd.read_csv(header_path,names=['column',''])['column'].values\n",
    "users = range(1,5)\n",
    "trials = range(1,7)\n",
    "all_data_1S = pd.DataFrame()\n",
    "all_data_2S = pd.DataFrame()\n",
    "all_data_5S = pd.DataFrame()\n",
    "all_data_10S = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for user in users:\n",
    "    for trial in trials:\n",
    "        if trial == 6:\n",
    "            file_name = path+'S'+str(user)+'-Drill'+'.dat'\n",
    "        else:\n",
    "            file_name = path+'S'+str(user)+'-ADL'+str(trial)+'.dat'\n",
    "        data, labels = read(file_name, header, user, trial)\n",
    "        columns = data.columns[~data.columns.isin(['user', 'trial','MILLISEC'])]\n",
    "        #we use a window of 11 elements\n",
    "        # Filtering using median filter\n",
    "        \n",
    "        all_features_1S = windowing(data, 1000, '1S', 500, labels, 11)\n",
    "        all_data_1S = pd.concat([all_data_1S, all_features_1S])\n",
    "        \n",
    "        all_features_2S = windowing(data, 2000, '2S', 1000, labels, 11)\n",
    "        all_data_2S = pd.concat([all_data_2S, all_features_2S])\n",
    "        \n",
    "        all_features_5S = windowing(data, 5000, '5S', 2500, labels, 11)\n",
    "        all_data_5S = pd.concat([all_data_5S, all_features_5S])\n",
    "        \n",
    "        all_features_10S = windowing(data, 10000, '10S', 5000, labels, 11)\n",
    "        all_data_10S = pd.concat([all_data_10S, all_features_10S])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_0S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_analisys = all_data_1S.filter(['Accelerometer_RKN^_accY_mean',\n",
    "'Accelerometer_HIP_accY_mean',\n",
    "'Accelerometer_BACK_accY_mean',\n",
    "'Accelerometer_RKN__accY_mean',\n",
    "'InertialMeasurementUnit_BACK_accY_mean',\n",
    "'InertialMeasurementUnit_BACK_gyroY_mean',\n",
    "'InertialMeasurementUnit_BACK_magneticY_mean',\n",
    "'Accelerometer_RKN^_accY_var',\n",
    "'Accelerometer_HIP_accY_var',\n",
    "'Accelerometer_BACK_accY_var',\n",
    "'Accelerometer_RKN__accY_var',\n",
    "'InertialMeasurementUnit_BACK_accY_var',\n",
    "'InertialMeasurementUnit_BACK_gyroY_var',\n",
    "'InertialMeasurementUnit_BACK_magneticY_var'\n",
    "], axis=1)\n",
    "corr = features_analisys.corr()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(features_analisys.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(features_analisys.columns)\n",
    "ax.set_yticklabels(features_analisys.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_analisys = all_data_1S.filter(['Accelerometer_RKN^_accY_mean',\n",
    "'Accelerometer_HIP_accY_mean',\n",
    "'Accelerometer_BACK_accY_mean',\n",
    "'InertialMeasurementUnit_BACK_accY_mean',\n",
    "'Accelerometer_RKN^_accY_var',\n",
    "'Accelerometer_HIP_accY_var',\n",
    "'Accelerometer_BACK_accY_var',\n",
    "'InertialMeasurementUnit_BACK_accY_var'\n",
    "], axis=1)\n",
    "corr = features_analisys.corr()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(features_analisys.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(features_analisys.columns)\n",
    "ax.set_yticklabels(features_analisys.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_1S_filtered = all_data_1S.filter(['Accelerometer_RKN^_accY_mean',\n",
    "'Accelerometer_HIP_accY_mean',\n",
    "'Accelerometer_BACK_accY_mean',\n",
    "'InertialMeasurementUnit_BACK_accY_mean',\n",
    "'Accelerometer_RKN^_accY_var',\n",
    "'Accelerometer_HIP_accY_var',\n",
    "'Accelerometer_BACK_accY_var',\n",
    "'InertialMeasurementUnit_BACK_accY_var',\n",
    "'label',\n",
    "'user',\n",
    "'trial'\n",
    "], axis=1)\n",
    "\n",
    "all_data_2S_filtered = all_data_2S.filter(['Accelerometer_RKN^_accY_mean',\n",
    "'Accelerometer_HIP_accY_mean',\n",
    "'Accelerometer_BACK_accY_mean',\n",
    "'InertialMeasurementUnit_BACK_accY_mean',\n",
    "'Accelerometer_RKN^_accY_var',\n",
    "'Accelerometer_HIP_accY_var',\n",
    "'Accelerometer_BACK_accY_var',\n",
    "'InertialMeasurementUnit_BACK_accY_var',\n",
    "'label',\n",
    "'user',\n",
    "'trial'\n",
    "], axis=1)\n",
    "\n",
    "all_data_5S_filtered = all_data_5S.filter(['Accelerometer_RKN^_accY_mean',\n",
    "'Accelerometer_HIP_accY_mean',\n",
    "'Accelerometer_BACK_accY_mean',\n",
    "'InertialMeasurementUnit_BACK_accY_mean',\n",
    "'Accelerometer_RKN^_accY_var',\n",
    "'Accelerometer_HIP_accY_var',\n",
    "'Accelerometer_BACK_accY_var',\n",
    "'InertialMeasurementUnit_BACK_accY_var',\n",
    "'label',\n",
    "'user',\n",
    "'trial'\n",
    "], axis=1)\n",
    "\n",
    "all_data_10S_filtered = all_data_10S.filter(['Accelerometer_RKN^_accY_mean',\n",
    "'Accelerometer_HIP_accY_mean',\n",
    "'Accelerometer_BACK_accY_mean',\n",
    "'InertialMeasurementUnit_BACK_accY_mean',\n",
    "'Accelerometer_RKN^_accY_var',\n",
    "'Accelerometer_HIP_accY_var',\n",
    "'Accelerometer_BACK_accY_var',\n",
    "'InertialMeasurementUnit_BACK_accY_var',\n",
    "'label',\n",
    "'user',\n",
    "'trial'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_1S_filtered.head())\n",
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_2S_filtered.head())\n",
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_5S_filtered.head())\n",
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_10S_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_1S_filtered.label.value_counts())\n",
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_2S_filtered.label.value_counts())\n",
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_5S_filtered.label.value_counts())\n",
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_10S_filtered.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_1S_filtered.trial.value_counts())\n",
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_2S_filtered.trial.value_counts())\n",
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_5S_filtered.trial.value_counts())\n",
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_10S_filtered.trial.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_1S_filtered.user.value_counts())\n",
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_2S_filtered.user.value_counts())\n",
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_5S_filtered.user.value_counts())\n",
    "print(\"\\n _______________________________________________________\")  \n",
    "print(all_data_10S_filtered.user.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate by class, see feature mean\n",
    "all_data_1S_0 = all_data_1S_filtered[all_data_1S_filtered.label==0]\n",
    "all_data_1S_1 = all_data_1S_filtered[all_data_1S_filtered.label==1]\n",
    "all_data_1S_2 = all_data_1S_filtered[all_data_1S_filtered.label==2]\n",
    "all_data_1S_4 = all_data_1S_filtered[all_data_1S_filtered.label==4]\n",
    "all_data_1S_5 = all_data_1S_filtered[all_data_1S_filtered.label==5]\n",
    "\n",
    "draw_col = 10\n",
    "sns.distplot(all_data_1S_0.iloc[:,draw_col], hist=False, kde=True, color='red')\n",
    "sns.distplot(all_data_1S_1.iloc[:,draw_col], hist=False, kde=True, color='green')\n",
    "sns.distplot(all_data_1S_2.iloc[:,draw_col], hist=False, kde=True, color='yellow')\n",
    "sns.distplot(all_data_1S_4.iloc[:,draw_col], hist=False, kde=True, color='blue')\n",
    "sns.distplot(all_data_1S_5.iloc[:,draw_col], hist=False, kde=True, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate by class, see feature mean\n",
    "all_data_2S_0 = all_data_2S_filtered[all_data_2S_filtered.label==0]\n",
    "all_data_2S_1 = all_data_2S_filtered[all_data_2S_filtered.label==1]\n",
    "all_data_2S_2 = all_data_2S_filtered[all_data_2S_filtered.label==2]\n",
    "all_data_2S_4 = all_data_2S_filtered[all_data_2S_filtered.label==4]\n",
    "all_data_2S_5 = all_data_2S_filtered[all_data_2S_filtered.label==5]\n",
    "\n",
    "draw_col = 10\n",
    "sns.distplot(all_data_2S_0.iloc[:,draw_col], hist=False, kde=True, color='red')\n",
    "sns.distplot(all_data_2S_1.iloc[:,draw_col], hist=False, kde=True, color='green')\n",
    "sns.distplot(all_data_2S_2.iloc[:,draw_col], hist=False, kde=True, color='yellow')\n",
    "sns.distplot(all_data_2S_4.iloc[:,draw_col], hist=False, kde=True, color='blue')\n",
    "sns.distplot(all_data_2S_5.iloc[:,draw_col], hist=False, kde=True, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate by class, see feature mean\n",
    "all_data_5S_0 = all_data_5S_filtered[all_data_5S_filtered.label==0]\n",
    "all_data_5S_1 = all_data_5S_filtered[all_data_5S_filtered.label==1]\n",
    "all_data_5S_2 = all_data_5S_filtered[all_data_5S_filtered.label==2]\n",
    "all_data_5S_4 = all_data_5S_filtered[all_data_5S_filtered.label==4]\n",
    "all_data_5S_5 = all_data_5S_filtered[all_data_5S_filtered.label==5]\n",
    "\n",
    "draw_col = 10\n",
    "sns.distplot(all_data_5S_0.iloc[:,draw_col], hist=False, kde=True, color='red')\n",
    "sns.distplot(all_data_5S_1.iloc[:,draw_col], hist=False, kde=True, color='green')\n",
    "sns.distplot(all_data_5S_2.iloc[:,draw_col], hist=False, kde=True, color='yellow')\n",
    "sns.distplot(all_data_5S_4.iloc[:,draw_col], hist=False, kde=True, color='blue')\n",
    "sns.distplot(all_data_5S_5.iloc[:,draw_col], hist=False, kde=True, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate by class, see feature mean\n",
    "all_data_10S_0 = all_data_10S_filtered[all_data_10S_filtered.label==0]\n",
    "all_data_10S_1 = all_data_10S_filtered[all_data_10S_filtered.label==1]\n",
    "all_data_10S_2 = all_data_10S_filtered[all_data_10S_filtered.label==2]\n",
    "all_data_10S_4 = all_data_10S_filtered[all_data_10S_filtered.label==4]\n",
    "all_data_10S_5 = all_data_10S_filtered[all_data_10S_filtered.label==5]\n",
    "\n",
    "draw_col = 10\n",
    "sns.distplot(all_data_10S_0.iloc[:,draw_col], hist=False, kde=True, color='red')\n",
    "sns.distplot(all_data_10S_1.iloc[:,draw_col], hist=False, kde=True, color='green')\n",
    "sns.distplot(all_data_10S_2.iloc[:,draw_col], hist=False, kde=True, color='yellow')\n",
    "sns.distplot(all_data_10S_4.iloc[:,draw_col], hist=False, kde=True, color='blue')\n",
    "sns.distplot(all_data_10S_5.iloc[:,draw_col], hist=False, kde=True, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#############################\")\n",
    "excercise_1(all_data_1S_filtered, 50)\n",
    "print(\"#############################\")\n",
    "excercise_1(all_data_2S_filtered, 50)\n",
    "print(\"#############################\")\n",
    "excercise_1(all_data_5S_filtered, 50)\n",
    "print(\"#############################\")\n",
    "excercise_1(all_data_10S_filtered, 50)\n",
    "print(\"#############################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#############################\")\n",
    "excercise_2(all_data_1S_filtered, 50)\n",
    "print(\"#############################\")\n",
    "excercise_2(all_data_2S_filtered, 50)\n",
    "print(\"#############################\")\n",
    "excercise_2(all_data_5S_filtered, 50)\n",
    "print(\"#############################\")\n",
    "excercise_2(all_data_10S_filtered, 50)\n",
    "print(\"#############################\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#############################\")\n",
    "excercise_3(all_data_1S_filtered, 50)\n",
    "print(\"#############################\")\n",
    "excercise_3(all_data_2S_filtered, 50)\n",
    "print(\"#############################\")\n",
    "excercise_3(all_data_5S_filtered, 50)\n",
    "print(\"#############################\")\n",
    "excercise_3(all_data_10S_filtered, 50)\n",
    "print(\"#############################\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
